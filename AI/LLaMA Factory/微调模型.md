
## 大模型的本质是什么？

大模型的本质是参数，输出的每一个字都是根据当前的词由函数计算出来的，参数决定了最后计算的结果准不准确。简单理解模型的知识和能力就存储在这些参数里面，模型训练也就是寻找优质参数的过程。

## 如何得到优质参数？


![[获取优质参数.png]]
## 如何知道模型学没学好


![[如何知道模型学没学好.png]]

## 什么是微调

在已经训练好的模型上继续调整模型参数

当已有模型不满足我们的任务要求时，我们有两种方式：
1. 随机初始化参数，从头训练，得到特定任务的新参数。（又慢又差）
2. LLM训练后的参数，增量微调，得到特定任务的新参数。（又快又好）


## 微调的流程

1. 选择基座模型
2. 准备训练数据
3. 微调方法
	- 全量微调：所有参数都要调整
	- 冻结微调：底层部分冻结不调整，仅调整输出或靠近输出层的部分
	- Lora微调：全部参数冻结不变，构造一个新的参数模块，训练好这个参数模块即可，两者参数合并就是新的参数。


## 如何挑选基座模型

1. 模型家族：qwen、llama3、deepseek......
2. 模型阶段：预训练模型、chat微模型、instruct微调......
3. 模型大小
4. 思考模式：推理模型、非推理模型

## 数据准备
### 数据关键

1. 数据质量比数据量重要
>不管怎么获取的数据，都需要进行数据质量评估

2. 数据量不要太多也不要太少
>少则欠拟合，多则遗忘，可以在数据集中添加一些通用性数据避免灾难性遗忘

3. 注意数据的多样性
>覆盖可能出现的各种问题、问法

### 数据方式

1. 人工准备
2. 模型生成 + 人工检查
3. 开源数据