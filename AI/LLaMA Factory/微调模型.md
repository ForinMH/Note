
## 大模型的本质是什么？

大模型的本质是参数，输出的每一个字都是根据当前的词由函数计算出来的，参数决定了最后计算的结果准不准确。简单理解模型的知识和能力就存储在这些参数里面，模型训练也就是寻找优质参数的过程。

## 如何得到优质参数？


![[获取优质参数.png]]
## 如何知道模型学没学好


![[如何知道模型学没学好.png]]

## 什么是微调

在已经训练好的模型上继续调整模型参数

当已有模型不满足我们的任务要求时，我们有两种方式：
1. 随机初始化参数，从头训练，得到特定任务的新参数。（又慢又差）
2. LLM训练后的参数，增量微调，得到特定任务的新参数。（又快又好）


## 微调的流程

1. 选择基座模型
2. 准备训练数据
3. 微调方法
	- 全量微调：所有参数都要调整
	- 冻结微调：底层部分冻结不调整，仅调整输出或靠近输出层的部分
	- Lora微调：全部参数冻结不变，构造一个新的参数模块，训练好这个参数模块即可，两者参数合并就是新的参数。


